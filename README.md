# bulk-robots-txt-generator-for-multiple-domains

Этот PHP скрипт предназначен для автоматической генерации файлов `robots.txt` для списка доменов. Он позволяет настроить общие правила запрета и разрешения для роботов, а также определяет поведение для различных поисковых агентов (user-agents).

## Описание

Скрипт использует массив доменов и наборы правил для создания уникальных файлов `robots.txt`. Правила перемешиваются случайным образом для каждого домена, что позволяет создавать разные конфигурации для каждого сайта.

## Функциональность

- **Генерация файлов `robots.txt`**: Создает файлы для каждого домена из списка.
- **Настройка правил**: Включает общие правила запрета (`Disallow`) и разрешения (`Allow`).
- **Настройка user-agents**: Определяет поведение для различных поисковых роботов.
- **Случайное перемешивание правил**: Создает уникальные комбинации правил для каждого домена.

## Установка и запуск

1. **Клонирование репозитория**:
git clone https://github.com/web-inwall/bulk-robots-txt-generator-for-multiple-domains.git

2. **Настройка скрипта**:
- Отредактируйте массив `$domains` в скрипте, чтобы включить список доменов, для которых вы хотите создать файлы `robots.txt`.
- Настройте правила запрета и разрешения в массивах `$common_rules` и `$allow_rules`.
- Настройте поведение для user-agents в массиве `$user_agents`.

3. **Запуск скрипта**:
php bulk-robots-txt-generator-for-multiple-domains.php

### Контактная информация

https://github.com/web-inwall/
https://t.me/inwall_ch